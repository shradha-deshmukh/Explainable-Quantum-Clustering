{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable Quantum Clustering Method to Model Medical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importing machine learning and quantum machine learning libraries\n",
    "2. dataset preparation: Assume that the dataset has been downloaded as a csv file onto a local computer,the dataset file can then be loaded into a pandas DataFrame.\n",
    "3. loading, preprocessing data\n",
    "4. Initally define the number of clusters(cluster center is Centroid), datapoints, and features\n",
    "5. Calculate distance from datapoint to centroids\n",
    "6. Updating centroids (Store old centroid to calculate new centroid)\n",
    "7. Assign the datapoint to a closest centroid.\n",
    "8. Calculate silhouette score for each datapoint(it should be positive value between 0 to 1)\n",
    "9. Calculate accuracy to show the cluster quality\n",
    "10. Install LIME : Provide explanations for individual predictions as a solution to determining trust.\n",
    "11. Pipeline is created for conveninence\n",
    "12. Tabular explainer is selected\n",
    "13. Explaining model predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from numpy import pi\n",
    "from qiskit import QuantumRegister, ClassicalRegister\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit import Aer, execute\n",
    "\n",
    "#qk-means Algorithm\n",
    "# Number of clusters\n",
    "k = 2\n",
    "# Number of training data\n",
    "n = data.shape[0]\n",
    "# Number of features in the data\n",
    "c = data.shape[1]\n",
    "\n",
    "# Generate random centers\n",
    "mean = np.mean(data, axis = 0)\n",
    "std = np.std(data, axis = 0)\n",
    "centers = np.random.randn(k,c)*std + mean\n",
    "\n",
    "# Static data to test\n",
    "centers = np.array([[1, 2,3,4,2,2,3], [6,5,6,7,6,5,6]])\n",
    "print(centers)\n",
    "\n",
    "# Plot the data and the centers generated as random\n",
    "colors=['green', 'blue']\n",
    "for i in range(n):\n",
    "    plt.scatter(data[i, 0], data[i,1], s=7, color = colors[int(category[i])])\n",
    "plt.scatter(centers[:,0], centers[:,1], marker='*', c='g', s=150)\n",
    "\n",
    "def point_centroid_distances(point, centroids):\n",
    "    \n",
    "    # Calculating theta and phi values\n",
    "    phi_list = [((x + 1) * pi / 2) for x in [point[0], centroids[0][0], centroids[1][0], centroids[2][0]]]\n",
    "    theta_list = [((x + 1) * pi / 2) for x in [point[1], centroids[0][1], centroids[1][1], centroids[2][1]]]\n",
    "\n",
    "    # Create a 3 qubit QuantumRegister - three for the vectors, and \n",
    "    # two for the ancillary qubit\n",
    "    qreg = QuantumRegister(3, 'qreg')\n",
    "\n",
    "    # Create a one bit ClassicalRegister to hold the result\n",
    "    # of the measurements\n",
    "    creg = ClassicalRegister(2, 'creg')\n",
    "\n",
    "    qc = QuantumCircuit(qreg, creg, name='qc')\n",
    "\n",
    "    # Get backend using the Aer provider\n",
    "    backend = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "    # Create list to hold the results\n",
    "    results_list = []\n",
    "\n",
    "    # Estimating distances from the new point to the centroids\n",
    "    for i in range(1, 4):\n",
    "        # Apply a Hadamard to the ancillary\n",
    "        qc.h(qreg[2])\n",
    "\n",
    "        # Encode new point and centroid\n",
    "        qc.u3(theta_list[0], phi_list[0], 0, qreg[0])           \n",
    "        qc.u3(theta_list[i], phi_list[i], 0, qreg[1]) \n",
    "\n",
    "        # Perform controlled swap\n",
    "        qc.cswap(qreg[2], qreg[0], qreg[1])\n",
    "        # Apply second Hadamard to ancillary\n",
    "        qc.h(qreg[2])\n",
    "\n",
    "        # Measure ancillary\n",
    "        qc.measure(qreg[2], creg[0])\n",
    "\n",
    "        # Reset qubits\n",
    "        qc.reset(qreg)\n",
    "\n",
    "        # Register and execute job\n",
    "        job = execute(qc, backend=backend, shots=5000)\n",
    "        result = job.result().get_counts(qc)\n",
    "        try:\n",
    "            results_list.append(result['1'])\n",
    "        except:\n",
    "            results_list.append(0)\n",
    "\n",
    "\n",
    "    return results_list\n",
    "\n",
    "centers_old = np.zeros(centers.shape) # to store old centers\n",
    "centers_new = deepcopy(centers) # Store new centers\n",
    "\n",
    "data.shape\n",
    "clusters = np.zeros(n)\n",
    "distances = np.zeros((n,k))\n",
    "\n",
    "error = np.linalg.norm(centers_new - centers_old)\n",
    "upper_error = error + 1\n",
    "\n",
    "# When, after an update, the estimate of that center stays the same, exit loop\n",
    "while (error + 0.02) < upper_error:\n",
    "    # Measure the distance to every center\n",
    "    \n",
    "    distances = np.array(list(map(lambda x: point_centroid_distances(x, centers), data)))\n",
    "\n",
    "    # Assign all training data to closest center\n",
    "    clusters = np.argmin(distances, axis = 1)\n",
    "    \n",
    "    centers_old = deepcopy(centers_new)\n",
    "    # Calculate mean for every cluster and update the center\n",
    "    for i in range(k):\n",
    "        centers_new[i] = np.mean(data[clusters == i], axis=0)\n",
    "    upper_error = deepcopy(error)\n",
    "    error = np.linalg.norm(centers_new - centers_old)\n",
    "    if error < 0.02:\n",
    "        break\n",
    "centers_new\n",
    "\n",
    "\n",
    "# calculate k using python, with the elbow method\n",
    "inertia = []\n",
    "\n",
    "# define our possible k values\n",
    "possible_K_values = [i for i in range(2,10)]\n",
    "\n",
    "# we start with 2\n",
    "\n",
    "# iterate through each of our values\n",
    "for each_value in possible_K_values:\n",
    "    \n",
    "    # iterate through, taking each value from \n",
    "    model = KMeans(n_clusters=each_value, init='k-means++',random_state=32)\n",
    "    \n",
    "    # fit it\n",
    "    model.fit(df_scaled)\n",
    "    \n",
    "    # append the inertia to our array\n",
    "    inertia.append(model.inertia_)\n",
    "\n",
    "plt.plot(possible_K_values, inertia)\n",
    "plt.title('The Elbow Method')\n",
    "\n",
    "plt.xlabel('Number of Clusters')\n",
    "\n",
    "plt.ylabel('Inertia')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# new model\n",
    "model = KMeans(n_clusters=2, init='k-means++',random_state=22)\n",
    "\n",
    "# re-fit our model\n",
    "model.fit(df_scaled)\n",
    "\n",
    "# compute an average silhouette score for each point\n",
    "silhouette_score_average = silhouette_score(df_scaled, model.predict(df_scaled))\n",
    "\n",
    "# lets see what that score it\n",
    "print(silhouette_score_average)\n",
    "\n",
    "\n",
    "# while that's nice, what does that tell us? there could still be a points with a negative value\n",
    "\n",
    "# let's see the points\n",
    "silhouette_score_individual = silhouette_samples(df_scaled, model.predict(df_scaled))\n",
    "\n",
    "\n",
    "# iterate through to find any negative values\n",
    "for each_value in silhouette_score_individual:\n",
    "    if each_value < 0:\n",
    "        print(f'We have found a negative silhouette score: {each_value}')\n",
    "        \n",
    "\n",
    "# Split dataset into training and testing datasets (Classical Method)\n",
    "from sklearn.model_selection import train_test_split #Split dataset into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, diagnosis, test_size=0.25, random_state=42)\n",
    "\n",
    "# Reindex \n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Convert Pandas DataFrame to Numpy ndarray\n",
    "X_train_values = X_train.values\n",
    "y_train_values = y_train.values\n",
    "X_test_values  = X_test.values\n",
    "y_test_values  = y_test.values\n",
    "\n",
    "X_train_values.shape, y_train_values.shape, X_test_values.shape, y_test_values.shape\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters = 2)\n",
    "km\n",
    "\n",
    "X_train_processed = km.fit_transform(X_train_values)\n",
    "X_test_processed  = km.fit_transform(X_test_values)\n",
    "\n",
    "y = km.fit_predict(X_train_processed, y_train)\n",
    "y\n",
    "score_k = km.score(X_test_processed, y_test)\n",
    "print(\"score = \", score_k)\n",
    "\n",
    "feature_importances_map = {'importance' : rfc.feature_importances_}\n",
    "feature_importances_df = pd.DataFrame(feature_importances_map)\n",
    "feature_importances_df.index = X_train.columns\n",
    "feature_importances_df.sort_values('importance', ascending=True, inplace=True)\n",
    "\n",
    "pip install lime\n",
    "\n",
    "from lime import lime_text\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "scale = Scale()\n",
    "sqrt  = Sqrt()\n",
    "\n",
    "machine_learning_pipeline = make_pipeline(scale, sqrt, km)\n",
    "class_names = ['Benign', 'Malignant']\n",
    "explainer = LimeTabularExplainer(feature_names=feature_names, \n",
    "                                 class_names=class_names, \n",
    "                                 training_data=X_train_values) \n",
    "\n",
    "def plot(exp, label=1):\n",
    "    '''\n",
    "    label 0 : explaining Benign\n",
    "    label 1 : explaining Malignant\n",
    "    '''\n",
    "    exp_list = exp.as_list()\n",
    "    fig = plt.figure()\n",
    "    vals = [x[1] for x in exp_list]\n",
    "    #print('vals:', vals)\n",
    "    names = [x[0] for x in exp_list]\n",
    "    #print('names:', names)\n",
    "    vals.reverse()\n",
    "    names.reverse()\n",
    "    colors = ['green' if x <= 0 else 'red' for x in vals]\n",
    "    pos = np.arange(len(exp_list)) + .5\n",
    "    plt.barh(pos, vals, align='center', color=colors)\n",
    "    plt.yticks(pos, names)\n",
    "    if exp.mode == \"classification\":\n",
    "        title = 'Local explanation for class {}'.format(exp.class_names[label])\n",
    "    else:\n",
    "        title = 'Local explanation'\n",
    "    plt.title(title)\n",
    "        \n",
    "    return fig\n",
    "\n",
    "def explain(feature_vector, machine_learning_pipeline, label=1): \n",
    "    '''\n",
    "    label 0 : explaining Benign\n",
    "    label 1 : explaining Malignant\n",
    "    '''\n",
    "    exp = explainer.explain_instance(feature_vector, machine_learning_pipeline.predict_proba, num_features=9)\n",
    "    fig = plot(exp, label) # explaining prediction as pyplot figure\n",
    "    exp.show_in_notebook(show_table=True, show_all=False) # explaining prediction in notebook format\n",
    "sample_M = raw_data.loc[5, feature_names]\n",
    "type(sample_M), sample_M\n",
    "p = machine_learning_pipeline.predict_proba(sample_M)\n",
    "p\n",
    "sample_M\n",
    "sample_M_processed = data_preprocessing_pipeline.fit_transform(sample_M.values.reshape(1, -1))\n",
    "sample_M_processed\n",
    "sample_B_1 = raw_data.loc[4, feature_names]\n",
    "explain(sample_B_1, machine_learning_pipeline, label=0)\n",
    "sample_B_1 = raw_data.loc[4, feature_names]\n",
    "explain(sample_B_1, machine_learning_pipeline, label=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
